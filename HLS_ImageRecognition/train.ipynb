{"metadata":{"language_info":{"name":"python","version":"3.8.5-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["from torch.autograd import Variable\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch\n","import torchvision\n","from torchvision import datasets, transforms\n","import torch.utils.data as data\n","import torchvision.models as models\n","import matplotlib.image as pli\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import numpy as np\n","from PIL import Image\n","from PIL import ImageOps\n","from PIL import ImageEnhance\n","import random\n","import math"],"metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["label_num = 6\n","train_file_path = 'trainingset_image'\n","class ImageSet(data.Dataset):\n","    def __init__(self):\n","        self.length = 500\n","\n","    def __getitem__(self, index):\n","        # print(index)\n","        label = index % label_num\n","        img_count = int(index / label_num) % 20 + 1\n","        # print(label)\n","\n","        img = Image.open(f'{train_file_path}/{label}_{img_count}.jpg')\n","        # plt.imshow(img)\n","        # plt.show()\n","        \n","        new_width = min(img.size[0], img.size[1])\n","        img = transforms.CenterCrop(new_width)(img)\n","        img = img.resize((34,34))\n","        img = transforms.Pad(8, padding_mode='edge')(img)\n","        img = transforms.RandomRotation(15)(img)\n","        img = transforms.CenterCrop(38)(img)\n","        img = transforms.RandomCrop((34,34))(img)\n","        img = transforms.RandomHorizontalFlip(0.5)(img)\n","        # img = transforms.Grayscale(num_output_channels=1)(img)\n","\n","        # img = transforms.Pad(12, padding_mode='edge')(img)\n","        # img = img.rotate(random.randint(0,15))\n","        # img = transforms.CenterCrop(80)(img)\n","        img = transforms.ToTensor()(img)\n","        img = transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])(img)\n","\n","        img += torch.randn(3,34,34) / 1000\n","\n","        # plt.imshow((img.permute(1, 2, 0).numpy() + 1) / 2)\n","        # print(img)\n","        # print(img.size())\n","        # plt.imshow((img[0].numpy() + 1) / 2)\n","        # plt.show()\n","        # print(aaa)\n","        \n","        return img, label\n","\n","    def __len__(self):\n","        return self.length"],"metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["batch_size = 256 if torch.cuda.is_available() else 8\n","train_loader = data.DataLoader(ImageSet(), batch_size=batch_size, shuffle=True)\n"],"metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class MiniCNN(nn.Module):\n","    def __init__(self):\n","        super(MiniCNN, self).__init__()\n","        # ConvLayer 1\n","        # 34\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels = 3,\n","                out_channels = 8,\n","                kernel_size = 3,\n","                stride = 1,\n","                padding = 0,\n","            ),\n","            # 32\n","            # nn.BatchNorm2d(6),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","            # 16\n","        )\n","        # ConvLayer 2\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels = self.conv1[0].out_channels,\n","                out_channels = 16,\n","                kernel_size = 3,\n","                stride = 1,\n","                padding = 0,\n","            ),\n","            # 14\n","            # nn.BatchNorm2d(12),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","            # 7\n","        )\n","        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n","        self.fc = nn.Linear(self.conv2[0].out_channels, label_num)\n","    \n","\n","    def forward(self, input):\n","        out = self.conv1(input)\n","        out = self.conv2(out)\n","        # out = self.conv3(out)\n","        # out = self.conv4(out)\n","        out = self.avg_pool(out)\n","        out = out.resize(out.size(0),out.size(1))\n","        out = self.fc(out)\n","        return out\n","\n","print(MiniCNN)"],"metadata":{"trusted":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["<class '__main__.MiniCNN'>\n"]}]},{"cell_type":"code","execution_count":630,"metadata":{},"outputs":[],"source":["convNet = MiniCNN()"]},{"cell_type":"code","source":["loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(convNet.parameters(), lr=0.01)\n"],"metadata":{"trusted":true},"execution_count":631,"outputs":[]},{"cell_type":"code","source":["convNet.train()\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n","convNet = convNet.to(device)\n","for i, (images, labels) in enumerate(train_loader):\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs = convNet(images)\n","    loss = loss_func(outputs, labels)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    predict = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n","    if i % 10 == 0:\n","        print(f\"i = {i},  loss = {loss}, labels = {labels}, predicts = {predict},  accuracy = {float(sum(labels == predict))/float(labels.size(0))}\")"],"metadata":{"trusted":true},"execution_count":633,"outputs":[{"output_type":"stream","name":"stdout","text":["i = 0,  loss = 0.5341327786445618, labels = tensor([2, 3, 4, 2, 1, 3, 3, 1]), predicts = tensor([2, 3, 2, 2, 1, 3, 3, 1]),  accuracy = 0.875\n","i = 10,  loss = 0.3344675898551941, labels = tensor([2, 5, 2, 0, 1, 5, 1, 1]), predicts = tensor([2, 5, 2, 0, 1, 5, 1, 1]),  accuracy = 1.0\n","i = 20,  loss = 0.29349228739738464, labels = tensor([2, 3, 2, 0, 0, 5, 4, 1]), predicts = tensor([2, 3, 2, 0, 0, 5, 4, 1]),  accuracy = 1.0\n","i = 30,  loss = 0.40547335147857666, labels = tensor([2, 2, 0, 2, 4, 0, 0, 4]), predicts = tensor([2, 2, 0, 2, 2, 0, 0, 2]),  accuracy = 0.75\n","i = 40,  loss = 0.20600035786628723, labels = tensor([5, 4, 2, 3, 3, 0, 2, 3]), predicts = tensor([5, 4, 2, 3, 3, 0, 2, 3]),  accuracy = 1.0\n","i = 50,  loss = 0.16593018174171448, labels = tensor([1, 3, 2, 2, 0, 5, 5, 2]), predicts = tensor([1, 3, 2, 4, 0, 5, 5, 2]),  accuracy = 0.875\n","i = 60,  loss = 0.1006302759051323, labels = tensor([3, 0, 2, 4, 3, 5, 1, 0]), predicts = tensor([3, 0, 2, 4, 3, 5, 1, 0]),  accuracy = 1.0\n"]}]},{"cell_type":"code","source":["# 保存模型， 请谨慎操作， 会覆盖文件中的模型\n","torch.save(convNet.state_dict(), './ConvNet.model')"],"metadata":{"trusted":true},"execution_count":635,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":6}],"source":["# 加载模型\n","\n","convNet  = MiniCNN()\n","convNet.load_state_dict(torch.load('./ConvNet.model'))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["label_num = 6\n","file_path = 'trainingset_image'\n","class testSet(data.Dataset):\n","    def __init__(self):\n","        self.length = 6\n","\n","    def __getitem__(self, index):\n","        # print(index)\n","\n","        img = Image.open(f'{file_path}/{index}_21.jpg')\n","        plt.imshow(img)\n","        plt.show()\n","        \n","        new_width = min(img.size[0], img.size[1])\n","        img = transforms.CenterCrop(new_width)(img)\n","        img = img.resize((34,34))\n","        \n","        # plt.imshow(img)\n","        # plt.show()\n","        # print(img)\n","        # img = transforms.Grayscale(num_output_channels=1)(img)\n","        img = transforms.ToTensor()(img)\n","        img = transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])(img)\n","\n","        # plt.imshow((img[0].numpy() + 1) / 2)\n","        print(max(img))\n","        print(min(img))\n","        plt.imshow((img.permute(1, 2, 0).numpy() + 1) / 2)\n","        plt.show()\n","        # print(img)\n","       \n","        \n","        return img, index\n","\n","    def __len__(self):\n","        return self.length\n","\n","test_loader = data.DataLoader(testSet(), batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'trainingset_image/0_21.jpg'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-8e3ae3affeb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconvNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-d3d48350c332>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# print(index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{file_path}/{index}_21.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trainingset_image/0_21.jpg'"]}],"source":["convNet.eval()\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n","convNet = convNet.to(device)\n","for i, (images, index) in enumerate(test_loader):\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs = convNet(images)\n","\n","    predict = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n","    \n","    print(f\"i = {index},   predict = {predict}\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["<generator object Module.parameters at 0x7fa3188afcf0>\n"]}],"source":["print(convNet.parameters())"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def torch_tensor_to_cpp(t):\n","    return str(t).replace('[','{').replace(']','}').replace('.,',',').replace('.}','}').replace('tensor(','').replace(', dtype=torch.float64)','').replace(')','')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["torch.set_printoptions(threshold=10000000000)\n","with open('layers_weight.h', 'w') as f:\n","    for name, data in convNet.named_parameters():\n","        array_str = torch_tensor_to_cpp(data.data)\n","        # print(array_str)\n","        f.write(f\"\"\"\n","        float layer{name.replace('.','_')}{str(data.size()).replace('torch.Size(','').replace(')','').replace(', ','][')}=\n","        {array_str};\n","        \"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}